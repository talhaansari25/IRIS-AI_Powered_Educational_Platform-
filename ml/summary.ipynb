{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: machine learning is a lot more than just learning but it's also about understanding and reasoning. today we will learn about the basics of machines learning and how to learn from the past data and do what humans can do and much faster well that'd be called k nearest neighbors so we can say that paul likes the song with fast tempo and soaring intensity while he dislikes it with relaxed intensity and light intensity so now we know the unknown song b is not correct so the choices unclear correct we could easily classify song\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# Check if GPU is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the T5 model and tokenizer\n",
    "model_name = \"t5-small\"  # You can use \"t5-base\" or \"t5-large\" for better performance, but it's slower\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Function for summarizing the text\n",
    "def summarize_text(text):\n",
    "    # Preprocess the text: adding the \"summarize\" prefix to the input\n",
    "    input_text = \"summarize in 5 sentence: \" + text\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "    \n",
    "    # Generate the summary (adjust max_length as needed)\n",
    "    summary_ids = model.generate(\n",
    "        inputs['input_ids'], \n",
    "        max_length=500,  # Set max length for the summary\n",
    "        num_beams=4, \n",
    "        no_repeat_ngram_size=2,  # Avoid repeating n-grams in the output\n",
    "        length_penalty=2.0, \n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    # Decode the summary and return it\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Example text to summarize\n",
    "text = \"\"\"\n",
    "we know humans learn from their past experiences and machines follow instructions given by humans but what if humans can train the machines to learn from the past data and do what humans can do and much faster well that's called machine learning but it's a lot more than just learning it's also about understanding and reasoning so today we will learn about the basics of machine learning so that's paul he loves listening to new songs he either likes them or dislikes them paul decides this on the basis of the song's tempo genre intensity and the gender of voice for simplicity let's just use tempo and intensity for now so here tempo is on the x axis ranging from relaxed to fast whereas intensity is on the y axis ranging from light to soaring we see that paul likes the song with fast tempo and soaring intensity while\n",
    "\"\"\"\n",
    "\n",
    "# Summarize the text\n",
    "summary = summarize_text(text)\n",
    "print(\"Summary:\", summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
